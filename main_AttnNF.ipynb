{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import helperfunctions_ATTNNF as helper\n",
    "\n",
    "import analyse_EEGprepost as geegpp\n",
    "import analyse_CohMotEpochEEG_Prepost as geeg_cohmotepoch\n",
    "import analyse_EEGduringNF as geegdnf\n",
    "import analyse_visualsearchtask as avissearch\n",
    "import analyse_nbacktask as anback\n",
    "import analyse_motiontask as analyse_motiontask\n",
    "import analyseNeurofeedback as analyse_NF\n",
    "import analyse_EEGsingletrialwavelets as analyse_sustattn\n",
    "import CorrelationAnalyses as analyse_corr\n",
    "import RSA as RSA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# setup generic settings\n",
    "attntrained = 1  # 0 = Space, 1 = Feature, 2 = Sham\n",
    "settings = helper.SetupMetaData(attntrained)\n",
    "print(\"Analysing Data for condition train: \" + settings.string_attntrained[settings.attntrained])\n",
    "\n",
    "# Some settings for how things will run\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# make plots come out correctly in notebook:\n",
    "# %matplotlib qt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analysing Data for condition train: Feature\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: During NF stats. -NF flicker\n",
    "# TODO: Get working on Neurodesk\n",
    "# TODO: Get working on neurodesk again. \n",
    "# TODO: Statistical tests for wavelets (time in each state)\n",
    "# TODO: individual trial independance of spatial and feature based-attention neurofeedback - how correlated are they really?\n",
    "# TODO: look at differences between classifiable and unclassifiable participants."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "######## Decide which single subject analyses to do ########\n",
    "\n",
    "# analyse_behaviour_prepost = True # Analyse Behaviour Pre Vs. Post Training\n",
    "analyse_behaviour_prepost = False  # Analyse Behaviour Pre Vs. Post Training\n",
    "#\n",
    "# analyse_behaviour_duringNF = True # Analyse Behaviour during Training\n",
    "analyse_behaviour_duringNF = False  # Analyse Behaviour duringTraining\n",
    "#\n",
    "# analyse_EEG_prepost =True # analyse EEG Pre Vs. Post Training\n",
    "analyse_EEG_prepost = True  # analyse EEG Pre Vs. Post Training\n",
    "#\n",
    "# analyse_EEG_prepost_motepochs =True # analyse EEG Pre Vs. Post Training (coherent motion) geeg_cohmotepoch\n",
    "analyse_EEG_prepost_motepochs = False  # analyse EEG Pre Vs. Post Training\n",
    "\n",
    "# analyse_EEG_duringNF = True # analyse EEG during Neurofeedback\n",
    "analyse_EEG_duringNF = False  # analyse EEG during Neurofeedback\n",
    "#\n",
    "# analyse_visualsearchtask = True # Analyse Visual Search Task\n",
    "analyse_visualsearchtask = False  # Analyse Visual Search Task\n",
    "\n",
    "# analyse_nbacktask = True # Analyse N-back Task\n",
    "analyse_nbacktask = False  # Analyse N-back Task\n",
    "\n",
    "# analyse_Neurofeedback = True # Analyse Neurofeedback and sustained attention\n",
    "analyse_Neurofeedback = False  # Analyse Neurofeedback and sustained attention\n",
    "\n",
    "# analyse_subjectRSA = True\n",
    "analyse_subjectRSA = False\n",
    "\n",
    "# analyse_singletrialEEG = True\n",
    "analyse_singletrialEEG = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "######## Decide which group analyses to do ########\n",
    "\n",
    "# collate_behaviour_prepost = True  # Collate Behaviour Pre Vs. Post Training\n",
    "collate_behaviour_prepost = False  # Collate Behaviour Pre Vs. Post Training\n",
    "#\n",
    "# collate_behaviour_duringNF = True # Collate Behaviour during Training\n",
    "collate_behaviour_duringNF = False  # Collate Behaviour during Training\n",
    "#\n",
    "# collateEEGprepost = True # Collate EEG Pre Vs. Post Training across subjects\n",
    "collateEEGprepost = False  # Collate EEG Pre Vs. Post Training across subjects\n",
    "\n",
    "# collateEEGprepost_motioncoherenceepochs = True # Collate EEG Pre Vs. Post Training across subjects\n",
    "collateEEGprepost_motioncoherenceepochs = False  # Collate EEG Pre Vs. Post Training across subjects\n",
    "\n",
    "# collateEEG_duringNF = True  # Collate EEG during Neurofeedback\n",
    "collateEEG_duringNF = False  # Collate EEG during Neurofeedback\n",
    "\n",
    "# collate_visualsearchtask = True # Collate Visual Search results\n",
    "collate_visualsearchtask = False  # Collate Visual Search results\n",
    "#\n",
    "# collate_nbacktask = True  # Analyse N-back Task\n",
    "collate_nbacktask = False  # Analyse N-back Task\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "######## Decide which group comparison analyses to do ########\n",
    "\n",
    "# classification_acc_correlations = True # Assess whether classification accuracy correlated with training effects\n",
    "classification_acc_correlations = False  # Assess whether classification accuracy correlated with training effects\n",
    "\n",
    "# collate_Neurofeedback = True # collate Neurofeedback and sustained attention\n",
    "collate_Neurofeedback = False  # collate Neurofeedback and sustained attention\n",
    "\n",
    "# collate_behaviour_prepost_compare = True # Collate Behaviour Pre Vs. Post Training compare training groups\n",
    "collate_behaviour_prepost_compare = False  # Collate Behaviour Pre Vs. Post Training compare training groups\n",
    "\n",
    "# collate_behaviour_duringNF_compare = True # Collate Behaviour during Training compare training groups\n",
    "collate_behaviour_duringNF_compare = False  # Collate Behaviour during Training compare training groups\n",
    "\n",
    "# collateEEGprepostcompare = True # Collate EEG Pre Vs. Post Training across subjects\n",
    "collateEEGprepostcompare = False  # Collate EEG Pre Vs. Post Training across subjects\n",
    "\n",
    "# collate_RSA = True\n",
    "collate_RSA = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "##### iterate through subjects for individual subject analyses #####\n",
    "\n",
    "for sub_count, sub_val in enumerate(settings.subsIDX):\n",
    "    print(sub_val)\n",
    "    plt.close('all')\n",
    "    if analyse_behaviour_prepost:\n",
    "        test_train = 0\n",
    "        analyse_motiontask.run(settings, sub_val, test_train)\n",
    "\n",
    "    if analyse_behaviour_duringNF:\n",
    "        test_train = 1\n",
    "        analyse_motiontask.run(settings, sub_val, test_train)\n",
    "\n",
    "    if analyse_Neurofeedback:\n",
    "        analyse_NF.run(settings, sub_val)\n",
    "\n",
    "    if analyse_EEG_prepost:\n",
    "        geegpp.analyseEEGprepost(settings, sub_val)\n",
    "\n",
    "    if analyse_EEG_prepost_motepochs:\n",
    "        geeg_cohmotepoch.analyseEEGprepost(settings, sub_val)\n",
    "\n",
    "    if analyse_EEG_duringNF:\n",
    "        geegdnf.analyseEEG_duringNF(settings, sub_val)\n",
    "\n",
    "    if analyse_visualsearchtask:\n",
    "        avissearch.analyse_visualsearchtask(settings, sub_val)\n",
    "\n",
    "    if analyse_nbacktask:\n",
    "        anback.analyse_nbacktask(settings, sub_val)\n",
    "\n",
    "    if analyse_subjectRSA:\n",
    "        RSA.participantRSA(settings, sub_val)\n",
    "\n",
    "    if analyse_singletrialEEG:\n",
    "        analyse_sustattn.analyseEEGprepost(settings, sub_val)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n",
      "analysing SSVEP amplitudes pre Vs. post training\n",
      "1\n",
      "sub-04_task-AttnNFMotion_day-1_phase-Test\n",
      "Extracting parameters from //home/user/Desktop/neurodesktop-storage/VISATTNNF/Data/TrainFeature/sub-04/eeg/sub-04_task-AttnNFMotion_day-1_phase-Test_eeg0.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 2240447  =      0.000 ...  1867.039 secs...\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Iz, Oz, POz, O1, O2, PO3, PO4, PO7, PO8, TRIG\n",
      " chs: 10 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 600.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 10\n",
      " projs: []\n",
      " sfreq: 1200.0 Hz\n",
      ">\n",
      "Trigger channel has a non-zero initial value of 254 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1580 events found\n",
      "Event IDs: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24 101 102 103 104 121 122 123 124 201 202 203 204\n",
      " 250 254]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/neurodesktop-storage/VISATTNNF/Analysis/AttentionNeurofeedbackAnalysis/helperfunctions_ATTNNF.py:314: RuntimeWarning: More events than default colors available. You should pass a list of unique colors.\n",
      "  mne.viz.plot_events(events, raw.info['sfreq'], raw.first_samp)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1580 events, first five:\n",
      "[[33531     0   104]\n",
      " [34728     0   122]\n",
      " [35437     0    24]\n",
      " [36810     0    16]\n",
      " [38118     0    21]]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 45.05 Hz)\n",
      "- Filter length: 39601 samples (33.001 sec)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/neurodesktop-storage/VISATTNNF/Analysis/AttentionNeurofeedbackAnalysis/helperfunctions_ATTNNF.py:416: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "192 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 192 events and 12001 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['Iz']\n",
      "1 bad epochs dropped\n",
      "Loading data for 47 events and 12001 original time points ...\n",
      "Loading data for 48 events and 12001 original time points ...\n",
      "Loading data for 48 events and 12001 original time points ...\n",
      "Loading data for 48 events and 12001 original time points ...\n",
      "4\n",
      "sub-04_task-AttnNFMotion_day-4_phase-Test\n",
      "Extracting parameters from //home/user/Desktop/neurodesktop-storage/VISATTNNF/Data/TrainFeature/sub-04/eeg/sub-04_task-AttnNFMotion_day-4_phase-Test_eeg0.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 2266559  =      0.000 ...  1888.799 secs...\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Iz, Oz, POz, O1, O2, PO3, PO4, PO7, PO8, TRIG\n",
      " chs: 10 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 600.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 10\n",
      " projs: []\n",
      " sfreq: 1200.0 Hz\n",
      ">\n",
      "Trigger channel has a non-zero initial value of 254 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1922 events found\n",
      "Event IDs: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24 101 102 103 104 121 122 123 124 201 202 203 204\n",
      " 250 254]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/neurodesktop-storage/VISATTNNF/Analysis/AttentionNeurofeedbackAnalysis/helperfunctions_ATTNNF.py:314: RuntimeWarning: More events than default colors available. You should pass a list of unique colors.\n",
      "  mne.viz.plot_events(events, raw.info['sfreq'], raw.first_samp)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1922 events, first five:\n",
      "[[34606     0   101]\n",
      " [35804     0   121]\n",
      " [36446     0    10]\n",
      " [37694     0    12]\n",
      " [39027     0     9]]\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 45.05 Hz)\n",
      "- Filter length: 39601 samples (33.001 sec)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/neurodesktop-storage/VISATTNNF/Analysis/AttentionNeurofeedbackAnalysis/helperfunctions_ATTNNF.py:416: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "192 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 192 events and 12001 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['PO3', 'PO7']\n",
      "    Rejecting  epoch based on EEG : ['Oz', 'POz', 'O1', 'O2', 'PO3', 'PO4', 'PO7']\n",
      "2 bad epochs dropped\n",
      "Loading data for 48 events and 12001 original time points ...\n",
      "Loading data for 46 events and 12001 original time points ...\n",
      "Loading data for 48 events and 12001 original time points ...\n",
      "Loading data for 48 events and 12001 original time points ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "##### Collate results across all subjects analyses #####\n",
    "\n",
    "# Collate pre-post motion task behaviour\n",
    "if collate_behaviour_prepost:\n",
    "    analyse_motiontask.collate_behaviour_prepost(settings)\n",
    "\n",
    "# Compare pre-post motion task behaviour between conditions.\n",
    "if collate_behaviour_prepost_compare:\n",
    "    analyse_motiontask.collate_behaviour_prepost_compare(settings)\n",
    "\n",
    "# Collate during Neurofeedback motion task behaviour\n",
    "if collate_behaviour_duringNF:\n",
    "    analyse_motiontask.collate_behaviour_duringNF(settings)\n",
    "\n",
    "# Compare during Neurofeedback motion task behaviour between conditions.\n",
    "if collate_behaviour_duringNF_compare:\n",
    "    analyse_motiontask.collate_behaviour_duringNF_compare(settings)\n",
    "\n",
    "# Collate the neurofeedback we presented.\n",
    "if collate_Neurofeedback:\n",
    "    analyse_NF.collate_Neurofeedback(settings)\n",
    "\n",
    "# Collate pre-post motion task EEG\n",
    "if collateEEGprepost:\n",
    "    geegpp.collateEEGprepost(settings)\n",
    "\n",
    "# Collate pre-post motion task EEG - motion coherence\n",
    "if collateEEGprepost_motioncoherenceepochs:\n",
    "    geeg_cohmotepoch.collateEEGprepost(settings)\n",
    "\n",
    "# Compare pre-post motion task EEG between training conditions\n",
    "if collateEEGprepostcompare:\n",
    "    geegpp.collateEEGprepostcompare(settings)\n",
    "\n",
    "# Collate during Neurofeedback motion task EEG\n",
    "if collateEEG_duringNF:\n",
    "    geegdnf.collateEEG_duringNF(settings)\n",
    "\n",
    "# Collate Visual Search Task Behaviour\n",
    "if collate_visualsearchtask:\n",
    "    avissearch.collate_visualsearchtask(settings)\n",
    "\n",
    "# Collate N-Back Task Behaviour\n",
    "if collate_nbacktask:\n",
    "    anback.collate_nbacktask(settings)\n",
    "\n",
    "if classification_acc_correlations:\n",
    "    analyse_corr.classification_acc_correlations(settings)\n",
    "\n",
    "# Collate RSA\n",
    "if collate_RSA:\n",
    "    RSA.collate_RSA(settings)\n",
    "    RSA.collate_RSA_bybehave(settings)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('mne': conda)"
  },
  "interpreter": {
   "hash": "d985d9ec64974553f71e81379d0d8fdbdc6224bdf792e1e7dee8e50647cb1463"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}